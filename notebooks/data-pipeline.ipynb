{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Housekeeping",
   "id": "9480007ff6b03490"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Library imports",
   "id": "46e4e872288cde3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO: use %store mydf and %store -r mydf (and also del in the first notebook) to divide the processes in the separate notebooks\n",
    "\n",
    "if False:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install -r requirements.txt"
   ],
   "id": "4469793d2fa6c5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from colorama import Fore, Style\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Machine Learning - Core\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "\n",
    "# Statistical & Data Processing\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Model Interpretability\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from supertree import SuperTree\n",
    "\n",
    "#Features selection\n",
    "import shap\n",
    "\n",
    "# Custom Functions\n",
    "from functions import (\n",
    "    random_forest_benchmark,\n",
    "    xgboost_benchmark,\n",
    "    adaboost_benchmark,\n",
    "    gradient_boosting_benchmark,\n",
    "    lightgbm_benchmark,\n",
    "    nn_feature_search,\n",
    "    explain_with_lime,\n",
    "    explain_with_shap,\n",
    "    cross_validate_feature_cutoffs,\n",
    "    plot_feature_cutoff_comparison,\n",
    "    plot_model_comparison_heatmap,\n",
    "    plot_residuals_analysis,\n",
    "    plot_prediction_intervals,\n",
    "    plot_learning_curves,\n",
    "    feature_selection_pipeline,\n",
    "    final_battle,\n",
    "    set_global_seeds,\n",
    "    get_taxonomic_level,\n",
    "    filter_features_by_level,\n",
    "    stochastic_gradient_boosting_benchmark,\n",
    "    kernel_random_forest_benchmark,\n",
    "    compare_feature_selection_methods,\n",
    "    find_best_evaluation_metric\n",
    ")\n",
    "\n",
    "#Importing Master Seed 3004\n",
    "from functions import MASTER_SEED"
   ],
   "id": "bb41f796b4a69652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Optional Imports (for specific analyses)\n",
    "\n",
    "These imports are used for specific visualizations and analyses that may not be needed in every run."
   ],
   "id": "30f77ba687f37b53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optional: Advanced Visualizations\n",
    "import collections  # Built-in, no install needed\n",
    "\n",
    "# Note: Most visualization functions are now in functions.py\n",
    "# and imported above in the main imports cell"
   ],
   "id": "a9c69f777036af7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Settings",
   "id": "575ccc90aa0bfdf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "print(Style.RESET_ALL)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus or False: #<- Change to True if you want to torture your computer (:\n",
    "    RUN_NN = True\n",
    "    print(\"GPU found\")\n",
    "else:\n",
    "    RUN_NN = False"
   ],
   "id": "89db602f0dab6725",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set global random seeds for reproducibility\n",
    "set_global_seeds(MASTER_SEED)"
   ],
   "id": "d102bc15ac644f03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data imports\n",
    "Data was manually edited, to convert the mpa411.txt TSV format to a CSV format. Otherwise, Pandas was loading it as a single column, somehow. The first row, containing only \"#mpa_vJun23_CHOCOPhlAnSGB_202403\" was removed."
   ],
   "id": "c7b8faf905ca9d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('../data/raw/MAI3004_lucki_mpa411.csv')\n",
    "metadata = pd.read_csv('../data/raw/MAI3004_lucki_metadata_safe.csv')\n",
    "print(\n",
    "    f\"Data successfully imported. \\n shape of data: {data.shape} \\n \"\n",
    "    f\"Shape of metadata: {metadata.shape}\"\n",
    ")\n",
    "\n",
    "assert data.shape == (6903, 932), \"Data has the wrong shape. Check the CSV formatting.\"\n",
    "assert metadata.shape == (930, 6), \"Metadata has the wrong shape. Check the CSV formatting.\""
   ],
   "id": "5bbaa44b5505c14d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data preprocessing",
   "id": "3e46d0f8f6bbecea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merge data and metadata",
   "id": "ce6927d16a5c5e0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_cols = [col for col in data.columns if col.startswith(\"mpa411_\")]\n",
    "\n",
    "sample_abundances = (\n",
    "    data[['clade_name'] + sample_cols]\n",
    "    .set_index('clade_name')\n",
    "    .transpose()\n",
    "    .rename_axis('original_sample_id')\n",
    "    .reset_index()\n",
    "    .rename(columns={'original_sample_id': 'sample_id'})\n",
    ")\n",
    "\n",
    "sample_abundances[\"sample_id\"] = (\n",
    "    sample_abundances[\"sample_id\"].str.removeprefix(\n",
    "        \"mpa411_\",\n",
    "    )\n",
    ")\n",
    "\n",
    "metadata_common = metadata[\n",
    "    metadata[\"sample_id\"].isin(sample_abundances[\"sample_id\"])\n",
    "].copy()\n",
    "merged_samples = metadata_common.merge(\n",
    "    sample_abundances,\n",
    "    on=\"sample_id\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "merged_samples.drop(columns=['year_of_birth', 'body_product'], inplace=True)\n",
    "\n",
    "print(f\"Metadata rows (original): {metadata.shape[0]}\")\n",
    "print(f\"Metadata rows with matching samples: {metadata_common.shape[0]}\")\n",
    "print(\n",
    "    f\"Metadata rows without matching samples: \"\n",
    "    f\"{metadata_common.shape[0]-metadata_common.shape[0]}\"\n",
    ")\n",
    "print(f\"Merged dataframe shape: {merged_samples.shape}\")"
   ],
   "id": "b194f7dea9503f60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged_samples.head()",
   "id": "5050c09aaa6b1902",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encoding",
   "id": "57c5a8d1b75e3a7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sex and family_ID\n",
    "encoded_samples = merged_samples.copy().dropna(subset=\"age_group_at_sample\")\n",
    "\n",
    "encoded_samples[\"sex\"] = (\n",
    "    encoded_samples[\"sex\"]\n",
    "    .fillna(\"unknown\")\n",
    "    .replace({\"female\": 1, \"male\": 0, \"unknown\": 2})\n",
    ")\n",
    "encoded_samples[\"family_id\"] = LabelEncoder().fit_transform(\n",
    "    encoded_samples[\"family_id\"]\n",
    ")\n"
   ],
   "id": "21d12bedeacaa973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Using days to better interpret the distance between age groups\n",
    "encoding_guide = {\n",
    "    '1-2 weeks': 10,\n",
    "    '4 weeks': 28,\n",
    "    '8 weeks': 56,\n",
    "    '4 months': 120,\n",
    "    '5 months': 150,\n",
    "    '6 months': 180,\n",
    "    '9 months': 270,\n",
    "    '11 months': 330,\n",
    "    '14 months': 420,\n",
    "}\n",
    "encoded_samples[\"age_group_at_sample\"] = encoded_samples[\"age_group_at_sample\"].replace(encoding_guide)\n",
    "encoded_samples[\"age_group_at_sample\"] = encoded_samples[\"age_group_at_sample\"].astype(int)\n",
    "# consider in interpretation that the distances between the real age bins are not the same as our age groups"
   ],
   "id": "105b5834cb05d0c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "leftovers = encoded_samples[encoded_samples[\"age_group_at_sample\"].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "if not leftovers.empty:\n",
    "\n",
    "    print(\"Age group encoding:\", leftovers[\"age_group_at_sample\"].unique())\n",
    "\n",
    "else:\n",
    "    print(\"Fallback encoding not needed\")\n"
   ],
   "id": "e4210134bbaa5548",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Missing check",
   "id": "8d80091855f14dad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "missing_table = (\n",
    "    encoded_samples.isna()\n",
    "    .sum()\n",
    "    .to_frame(name=\"missing_count\")\n",
    "    .assign(\n",
    "        missing_percent=lambda df: (\n",
    "            (df[\"missing_count\"] / encoded_samples.shape[0] * 100).round(2)\n",
    "        ),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"column\"})\n",
    "    .sort_values(\"missing_count\", ascending=False)\n",
    "    .query(\"missing_count != 0\")\n",
    ")\n",
    "\n",
    "if len(missing_table) > 0:\n",
    "    missing_table\n",
    "else:\n",
    "    print(\"No missing values detected.\")"
   ],
   "id": "e15a8480a24b2bed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Outlier check",
   "id": "e25680ba8579c076"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_cols = encoded_samples.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "q1 = encoded_samples[numeric_cols].quantile(0.25)\n",
    "q3 = encoded_samples[numeric_cols].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bounds = q1 - 1.5 * iqr\n",
    "upper_bounds = q3 + 1.5 * iqr\n",
    "\n",
    "outlier_mask = (\n",
    "    (encoded_samples[numeric_cols] < lower_bounds)\n",
    "    | (encoded_samples[numeric_cols] > upper_bounds)\n",
    ")\n",
    "outlier_counts = outlier_mask.sum()\n",
    "outlier_percent = (outlier_counts / encoded_samples.shape[0] * 100).round(2)\n",
    "\n",
    "outlier_table = (\n",
    "    pd.DataFrame({\n",
    "        \"column\": numeric_cols,\n",
    "        \"lower_bound\": lower_bounds,\n",
    "        \"upper_bound\": upper_bounds,\n",
    "        \"outlier_count\": outlier_counts,\n",
    "        \"outlier_percent\": outlier_percent,\n",
    "    })\n",
    "    .query(\"outlier_count > 0\")\n",
    "    .sort_values(\"outlier_percent\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "outlier_table"
   ],
   "id": "cbd389835f6c4196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalisation check",
   "id": "731325d34c41d28c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "normalized_samples = encoded_samples.copy()\n",
    "print(\"Shapiro-Wilk Normality Test\")\n",
    "\n",
    "for column in numeric_cols:\n",
    "    data_nona = normalized_samples[column].dropna()\n",
    "    stat, p_value = stats.shapiro(data_nona)\n",
    "\n",
    "    if p_value > 0.05:\n",
    "        print(Fore.GREEN + f\"{column}: Normally Distributed (p={p_value:.4f})\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            Fore.RED\n",
    "            + f\"{column}: Not Normally Distributed (p={p_value:.4f})\"\n",
    "        )\n",
    "\n",
    "print(Style.RESET_ALL)"
   ],
   "id": "5e9daacd1258d402",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train-test split before pre-processing",
   "id": "1eaf9a9b3f36800c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_cols = normalized_samples.columns.difference([\"sample_id\", \"age_group_at_sample\"]) # These variables will get removed from X\n",
    "\n",
    "X = normalized_samples[feature_cols]\n",
    "Y = normalized_samples[\"age_group_at_sample\"]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=MASTER_SEED)\n",
    "train_indicies, test_indicies = next(gss.split(X, Y, groups=X['family_id']))\n",
    "X_train_raw = X.iloc[train_indicies]\n",
    "X_test_raw = X.iloc[test_indicies]\n",
    "Y_train = Y.iloc[train_indicies]\n",
    "Y_test = Y.iloc[test_indicies]\n",
    "\n",
    "assert X_train_raw.shape[1] == X_test_raw.shape[1], \"Feature columns do not match between train and test sets.\"\n",
    "assert X_train_raw.shape[0] == Y_train.shape[0] and X_test_raw.shape[0] == Y_test.shape[0], \"X and Y do not have the same length.\"\n",
    "\n",
    "print(\"Train shape:\", X_train_raw.shape, \"| Test shape:\", X_test_raw.shape)"
   ],
   "id": "c4dee78c5ba1f8a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalising data using clr transformation",
   "id": "ed4c77f18924e5d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bc3b0a0b3c12f072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = clr_transform(X_train_raw)\n",
    "X_test = clr_transform(X_test_raw)"
   ],
   "id": "f09b877ed4e3ea92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To activate back the raw data without normalisation, uncomment the following:\n",
    "# X_train = X_train_raw\n",
    "# X_test = X_test_raw"
   ],
   "id": "79ee9be31e8a67f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Shapiro-Wilk Normality Test (after Log Normalisation)\\n\")\n",
    "\n",
    "for col in X_train.columns:\n",
    "\n",
    "    # 1. Get the data for this column from both sets\n",
    "    train_data = X_train[col].dropna()\n",
    "    test_data = X_test[col].dropna()\n",
    "\n",
    "    # 2. Run Shapiro test on both\n",
    "    stat_train, p_train = stats.shapiro(train_data)\n",
    "    stat_test, p_test = stats.shapiro(test_data)\n",
    "\n",
    "    # 3. Determine status (Both must be > 0.05 to be truly \"Normal\")\n",
    "    is_train_normal = p_train > 0.05\n",
    "    is_test_normal = p_test > 0.05\n",
    "\n",
    "    # 4. Print Logic\n",
    "    # If both are Green\n",
    "    if is_train_normal and is_test_normal:\n",
    "        print(Fore.GREEN + f\"✔ {col}: Normal (Train p={p_train:.3f}, Test p={p_test:.3f})\")\n",
    "\n",
    "    # If one is Red (Mixed results)\n",
    "    elif is_train_normal or is_test_normal:\n",
    "        print(Fore.YELLOW + f\"⚠ {col}: Inconsistent (Train p={p_train:.3f}, Test p={p_test:.3f})\")\n",
    "\n",
    "    # If both are Red\n",
    "    else:\n",
    "        print(Fore.RED + f\"✘ {col}: Not Normal (Train p={p_train:.3f}, Test p={p_test:.3f})\")\n",
    "\n",
    "print(Style.RESET_ALL)"
   ],
   "id": "fa6e9891a7244692",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory data analysis",
   "id": "4a1f189981a14c32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(merged_samples.shape)\n",
    "merged_samples.head()"
   ],
   "id": "b51ebb0f5e843ab0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset overview\n",
    "print(\"Number of samples:\", len(merged_samples))\n",
    "print(\n",
    "    \"Number of unique families (family_id):\",\n",
    "    merged_samples[\"family_id\"].nunique(),\n",
    ")\n",
    "print(\"Number of columns (metadata + features):\", merged_samples.shape[1])"
   ],
   "id": "dd0a7c0d4b30ac90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Samples per family\n",
    "samples_per_family = merged_samples[\"family_id\"].value_counts()\n",
    "samples_per_family.describe()"
   ],
   "id": "cab8ee6f4c5c5141",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples_per_family.hist(bins=20)\n",
    "plt.xlabel(\"Number of samples per family\")\n",
    "plt.ylabel(\"Number of families\")\n",
    "plt.title(\"Distribution of samples per family\")\n",
    "plt.show()"
   ],
   "id": "e2dca505d4f84270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#distribution of age groups\n",
    "merged_samples[\"age_group_at_sample\"].value_counts(dropna=False)"
   ],
   "id": "4577d9d6277f945f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged_samples[\"age_group_at_sample\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of age groups\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "id": "cfbe617a8129c1f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#dimensionality and sparsity of the microbiome feature matrix\n",
    "metadata_cols = [\n",
    "    \"sample_id\",\n",
    "    \"family_id\",\n",
    "    \"sex\",\n",
    "    \"body_product\",\n",
    "    \"age_group_at_sample\",\n",
    "    \"year_of_birth\",\n",
    "]\n",
    "feature_cols = [c for c in merged_samples.columns if c not in metadata_cols]\n",
    "\n",
    "X = merged_samples[feature_cols]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Overall fraction of zeros:\", (X == 0).mean().mean())"
   ],
   "id": "af2e2266d2816929",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#number of observed taxa per sample\n",
    "nonzero_per_sample = (X > 0).sum(axis=1)\n",
    "nonzero_per_sample.describe()"
   ],
   "id": "f699e343d73f0658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nonzero_per_sample.hist(bins=50)\n",
    "plt.xlabel(\"Number of non-zero taxa per sample\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Non-zero taxa per sample\")\n",
    "plt.show()"
   ],
   "id": "e4b140e20b3947c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Total abundance per sample (sanity check)\n",
    "total_abundance = X.sum(axis=1)\n",
    "total_abundance.describe()"
   ],
   "id": "930baf2883062622",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_abundance.hist(bins=50)\n",
    "plt.xlabel(\"Total abundance per sample\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Total microbial abundance per sample\")\n",
    "plt.show()"
   ],
   "id": "7fb8bf983af9271a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution of feature prevalence\n",
    "feature_prevalence = (X > 0).sum(axis=0)\n",
    "feature_prevalence.describe()"
   ],
   "id": "1efbf636e26c98c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_prevalence.hist(bins=50)\n",
    "plt.xlabel(\"Number of samples in which taxon is present\")\n",
    "plt.ylabel(\"Number of taxa\")\n",
    "plt.title(\"Feature prevalence distribution\")\n",
    "plt.show()"
   ],
   "id": "523c8d30ead8b326",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution of non-zero abundances (log scale)\n",
    "\n",
    "nonzero_values = X.values[X.values > 0]\n",
    "plt.hist(np.log10(nonzero_values), bins=50)\n",
    "plt.xlabel(\"log10(abundance)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of non-zero abundances (log10 scale)\")\n",
    "plt.show()"
   ],
   "id": "4b0a5db6f68c207c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PCA visualization\n",
    "# Use a subset of features for speed\n",
    "prevalence = (X > 0).sum(axis=0)\n",
    "top_features = prevalence.sort_values(ascending=False).head(500).index\n",
    "\n",
    "X_sub = X[top_features]\n",
    "\n",
    "# Scale features\n",
    "X_scaled = StandardScaler().fit_transform(X_sub)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot\n",
    "age = merged_samples[\"age_group_at_sample\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca.iloc[:, 0], X_pca.iloc[:, 1],\n",
    "            c=pd.factorize(age)[0], cmap=\"viridis\", alpha=0.6)\n",
    "plt.colorbar(label=\"Age group (encoded)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA of samples colored by age group\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
   ],
   "id": "5258708d8e4993a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PCA on CLR-transformed data (training set)\n",
    "\n",
    "# Use only microbiome features (exclude metadata)\n",
    "meta_cols = [c for c in [\"sex\", \"family_id\"] if c in X_train.columns]\n",
    "micro_cols = [c for c in X_train.columns if c not in meta_cols]\n",
    "\n",
    "Xtr = X_train[micro_cols].copy()\n",
    "Xte = X_test[micro_cols].copy()\n",
    "\n",
    "# Optional: select top N most prevalent taxa (for speed)\n",
    "top_n = 500\n",
    "if top_n is not None:\n",
    "    prevalence = (Xtr > 0).sum(axis=0)\n",
    "    top_features = prevalence.sort_values(ascending=False).head(top_n).index\n",
    "    Xtr = Xtr[top_features]\n",
    "    Xte = Xte[top_features]\n",
    "\n",
    "# Convert to NumPy\n",
    "Xtr_np = Xtr.to_numpy()\n",
    "Xte_np = Xte.to_numpy()\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "Xtr_scaled = scaler.fit_transform(Xtr_np)\n",
    "Xte_scaled = scaler.transform(Xte_np)\n",
    "\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2, random_state=3004)\n",
    "Ztr = pca.fit_transform(Xtr_scaled)\n",
    "Zte = pca.transform(Xte_scaled)\n",
    "\n",
    "# Force NumPy output again\n",
    "Ztr = np.asarray(Ztr)\n",
    "Zte = np.asarray(Zte)\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_, \"| Cumulative:\", pca.explained_variance_ratio_.sum())\n",
    "print(\"PC1 range:\", Ztr[:, 0].min(), Ztr[:, 0].max())\n",
    "print(\"PC2 range:\", Ztr[:, 1].min(), Ztr[:, 1].max())\n",
    "\n",
    "# Plot (high readability)\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=110)\n",
    "\n",
    "sc = plt.scatter(\n",
    "    Ztr[:, 0],\n",
    "    Ztr[:, 1],\n",
    "    c=Y_train.values,\n",
    "    s=35,\n",
    "    cmap=\"viridis\",\n",
    "    alpha=0.85\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label(\"Age group (encoded)\", fontsize=12)\n",
    "cbar.ax.tick_params(labelsize=11)\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% variance explained)\", fontsize=13)\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% variance explained)\", fontsize=13)\n",
    "plt.title(\"PCA of CLR-transformed microbiome samples (training set)\", fontsize=15, pad=10)\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.grid(True, color=\"white\", alpha=0.3, linewidth=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "2e3cf0a18b8c6686",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary of EDA\n",
    "The dataset consists of 930 stool samples derived from multiple individuals across different families and contains approximately 6,900 microbiome features, making it a high-dimensional and highly sparse dataset. Each sample contains on average around 300 detected taxa, while the total microbial abundance per sample is relatively stable, indicating that sequencing depth is relatively consistent across samples.\n",
    "\n",
    "Most taxa are rare and occur in only a small fraction of samples, whereas a small subset of taxa is highly prevalent across the cohort. The distribution of non-zero abundances follows an approximately log-normal shape, which is typical for microbiome sequencing data (Lutz et al., 2022).\n",
    "\n",
    "An initial PCA projection based on the most prevalent taxa and raw abundance data does not reveal sharply separated clusters but shows a gradual age-related gradient, suggesting that age-related variation in microbiome composition is present but represents only a limited fraction of the total variance in the data.\n",
    "\n",
    "Because microbiome data are compositional in nature, a second PCA is later performed on CLR-transformed and standardized data in the preprocessing stage to obtain a compositionally valid low-dimensional representation for downstream analysis and modeling.\n"
   ],
   "id": "8c512758fa3316f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "2381b4b1ba25ffeb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filtering for features at the genus level",
   "id": "19ab7037222814aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_genus_raw = filter_features_by_level(X_train, max_level=\"Genus\")\n",
    "X_train_genus, _ = feature_selection_pipeline(X_train_genus_raw)\n",
    "X_test_genus = X_test[X_train_genus.columns]"
   ],
   "id": "84f7272b09571f7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Alternative: Using Taxonomic Level Functions\n",
    "\n",
    "Demonstrate filtering by different taxonomic levels using helper functions."
   ],
   "id": "cadac05267297d47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO: Do the filtering, and only after the CLR transformation\n",
    "# Example: Get taxonomic level of a feature\n",
    "sample_feature = X_train.columns[0]\n",
    "tax_level = get_taxonomic_level(sample_feature)\n",
    "print(f\"Feature: {sample_feature}\")\n",
    "print(f\"Taxonomic level: {tax_level}\")\n",
    "\n",
    "# Filter features by different taxonomic levels\n",
    "print(f\"\\nOriginal features: {X_train.shape[1]}\")\n",
    "\n",
    "X_train_family_raw = filter_features_by_level(X_train, max_level=\"Family\")\n",
    "X_train_family, _ = feature_selection_pipeline(X_train_family_raw)\n",
    "X_test_family = X_test[X_train_family.columns]\n",
    "print(f\"Family-level features: {X_train_family.shape[1]}\")\n",
    "\n",
    "X_train_order_raw = filter_features_by_level(X_train, max_level=\"Order\")\n",
    "X_train_order, _ = feature_selection_pipeline(X_train_family_raw)\n",
    "X_test_order = X_test[X_train_order.columns]\n",
    "print(f\"Order-level features: {X_train_order.shape[1]}\")\n",
    "\n",
    "X_train_species_raw = filter_features_by_level(X_train, max_level=\"Species\")\n",
    "X_train_species, _ = feature_selection_pipeline(X_train_species_raw)\n",
    "X_test_species = X_test[X_train_species.columns]\n",
    "print(f\"Species-level features: {X_train_species.shape[1]}\")\n",
    "\n",
    "X_train_phylum_raw = filter_features_by_level(X_train, max_level=\"Phylum\")\n",
    "X_train_phylum, _ = feature_selection_pipeline(X_train_phylum_raw)\n",
    "X_test_phylum = X_test[X_train_phylum.columns]\n",
    "print(f\"Phylum-level features: {X_train_species.shape[1]}\")\n",
    "\n",
    "X_train_class_raw = filter_features_by_level(X_train, max_level=\"Class\")\n",
    "X_train_class, _ = feature_selection_pipeline(X_train_class_raw)\n",
    "X_test_class = X_test[X_train_class.columns]\n",
    "print(f\"Phylum-level features: {X_train_species.shape[1]}\")"
   ],
   "id": "ab00767ea5790f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Genus Level: {X_train_genus.shape[1]} features | Family Level: {X_train_family.shape[1]} features | Order Level: {X_train_order.shape[1]} features | Species Level: {X_train_species.shape[1]}\")",
   "id": "b56d846b95969dc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Features used by model:\")\n",
    "print(X_train_genus.columns.tolist())"
   ],
   "id": "5ee7cd47f4b34205",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize model results tracking\n",
    "model_results = []\n",
    "print(\"Model results tracking initialized\")"
   ],
   "id": "de9ca9fa3f53da23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest Regressor with Train/Test split (Genus)",
   "id": "7c54cc858cd2ba26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Default starting parameters\n",
    "current_params = {\n",
    "    \"prevalence_thresh\": 0.05,\n",
    "    \"abundance_thresh\": 1e-4,\n",
    "    \"variance_thresh\": 1e-5,\n",
    "    \"corr_thresh\": 0.9\n",
    "}\n",
    "\n",
    "# Maximum perturbation for each parameter\n",
    "param_ranges = {\n",
    "    \"prevalence_thresh\": 0.01,\n",
    "    \"abundance_thresh\": 5e-5,\n",
    "    \"variance_thresh\": 5e-6,\n",
    "    \"corr_thresh\": 0.05\n",
    "}\n",
    "\n",
    "best_rmse = np.inf\n",
    "best_r2 = -np.inf\n",
    "results = []\n",
    "\n",
    "n_iterations = 50  # you can increase this for a more thorough search\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Random perturbation for all parameters\n",
    "    new_params = {\n",
    "        k: max(1e-9, current_params[k] + np.random.uniform(-param_ranges[k], param_ranges[k]))\n",
    "        for k in current_params\n",
    "    }\n",
    "    # Keep corr_thresh <= 0.99\n",
    "    if new_params[\"corr_thresh\"] >= 1.0:\n",
    "        new_params[\"corr_thresh\"] = 0.99\n",
    "\n",
    "    # Apply feature filtering\n",
    "    X_train_filtered, removed_features = feature_selection_pipeline(\n",
    "        X_train_genus_raw,\n",
    "        prevalence_thresh=new_params[\"prevalence_thresh\"],\n",
    "        abundance_thresh=new_params[\"abundance_thresh\"],\n",
    "        variance_thresh=new_params[\"variance_thresh\"],\n",
    "        corr_thresh=new_params[\"corr_thresh\"]\n",
    "    )\n",
    "    X_test_filtered = X_test[X_train_filtered.columns]\n",
    "\n",
    "    # Train a quick model\n",
    "    rf_temp = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train_filtered, Y_train)\n",
    "    preds = rf_temp.predict(X_test_filtered)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test, preds))\n",
    "    r2 = r2_score(Y_test, preds)\n",
    "\n",
    "    results.append({\n",
    "        **new_params,\n",
    "        \"rmse\": rmse,\n",
    "        \"r2\": r2,\n",
    "        \"n_features\": X_train_filtered.shape[1]\n",
    "    })\n",
    "\n",
    "    # Keep new params if performance improved\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_r2 = r2\n",
    "        current_params = new_params.copy()\n",
    "\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(f\"Iteration {i+1}: Best RMSE = {best_rmse:.2f}, Best R² = {best_r2:.3f}\")\n",
    "\n",
    "# Save all results for review\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nBest parameters found:\")\n",
    "print(current_params)\n",
    "print(f\"\\nBest RMSE: {best_rmse:.2f}\")\n",
    "print(f\"Best R²: {best_r2:.3f}\")"
   ],
   "id": "2c720ad8f0725339",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest Regressor with Train/Test split (Genus)",
   "id": "e077e5b218e4a990"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base model",
   "id": "88fca297271b907f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Base model\n",
    "rf_base = RandomForestRegressor(\n",
    "    random_state=MASTER_SEED,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "rf_base.fit(X_train_genus, Y_train)\n",
    "yhat_rf = rf_base.predict(X_test_genus)\n",
    "\n",
    "print(f\"Mean Squared Error: {mean_squared_error(Y_test, yhat_rf):.3f}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(mean_squared_error(Y_test, yhat_rf)):.3f}\")\n",
    "print(f\"R2 Score: {r2_score(Y_test, yhat_rf):.3f}\")\n"
   ],
   "id": "b660469d2056b08f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search for the best model",
   "id": "86151a1688ed0ad4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rf_results = random_forest_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {rf_results.best_params}\")"
   ],
   "id": "a2ee91c5480fd611",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Track Random Forest results\n",
    "model_results.append({\n",
    "    'model': 'Random Forest',\n",
    "    'rmse': rf_results.rmse,\n",
    "    'r2': rf_results.r2,\n",
    "    'best_params': rf_results.best_params,\n",
    "})"
   ],
   "id": "4a33be8a4f723d1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Mean Squared Error: {rf_results.rmse**2:.3f}\") # Squared because rmse is sqrt(mse)\n",
    "print(f\"Best CV RMSE: {rf_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {rf_results.r2:.3f}\")\n",
    "\n",
    "best_rf_model = rf_results.model\n",
    "yhat = rf_results.model.predict(X_test_genus)"
   ],
   "id": "68325170b5423c48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level RF)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4a0ffcec9e1e7b10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "residuals = Y_test - yhat\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=yhat, y=residuals, alpha=0.6)\n",
    "plt.axhline(0, linestyle=\"--\", color=\"red\")\n",
    "\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Predictions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ca6b8c6531d1dd3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importances = pd.Series(\n",
    "    best_rf_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances.head(top_n),\n",
    "    y=importances.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7671570c86eef1d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "st = SuperTree(\n",
    "    best_rf_model,\n",
    "    X_train_genus,\n",
    "    Y_train\n",
    ")\n",
    "\n",
    "st.show_tree(which_tree=0)"
   ],
   "id": "a57059aaeffd8734",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get predictions from each tree on the test set\n",
    "all_tree_preds = np.array([tree.predict(X_test_genus) for tree in best_rf_model.estimators_])\n",
    "\n",
    "# compute the mean prediction (Random Forest final prediction)\n",
    "rf_pred = all_tree_preds.mean(axis=0)\n",
    "\n",
    "# compute standard deviation per sample (uncertainty)\n",
    "rf_std = all_tree_preds.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# plot all tree predictions (semi-transparent lines)\n",
    "for i in range(all_tree_preds.shape[0]):\n",
    "    plt.plot(Y_test.values, all_tree_preds[i], 'o', color='lightgray', alpha=0.3)\n",
    "\n",
    "# plot Random Forest mean prediction\n",
    "plt.scatter(Y_test, rf_pred, color='blue', label='RF mean prediction', s=40)\n",
    "\n",
    "plt.errorbar(Y_test, rf_pred, yerr=rf_std, fmt='o', color='red', alpha=0.5, label='±1 std across trees')\n",
    "\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color='black', linestyle='--', label='Perfect prediction')\n",
    "\n",
    "plt.xlabel(\"Actual Age Group\")\n",
    "plt.ylabel(\"Predicted Age Group\")\n",
    "plt.title(\"Random Forest – Forest plot of tree predictions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "d7e42a342390226d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Alternative Models",
   "id": "9ddbce3ca67ff428"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## XGBoost Alternative",
   "id": "bffe2868e2c609b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Base model\n",
    "xgb_base = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=MASTER_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "X_train_clean = X_train_genus.copy()\n",
    "X_train_clean.columns = [re.sub('[^A-Za-z0-9_]+', '', str(col)) for col in X_train_clean.columns]\n",
    "X_test_clean = X_test_genus.copy()\n",
    "X_test_clean.columns = [re.sub('[^A-Za-z0-9_]+', '', str(col)) for col in X_test_clean.columns]\n",
    "\n",
    "\n",
    "xgb_base.fit(X_train_clean, Y_train)\n",
    "yhat_xgb = xgb_base.predict(X_test_clean)\n",
    "\n",
    "print(f\"Mean Squared Error: {mean_squared_error(Y_test, yhat_xgb):.3f}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(mean_squared_error(Y_test, yhat_xgb)):.3f}\")\n",
    "print(f\"R2 Score: {r2_score(Y_test, yhat_xgb):.3f}\")\n"
   ],
   "id": "5890850fd56bfcb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Best XGBoost Parameters Search",
   "id": "8a503bb6dc45360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "xgboost_results = xgboost_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "print(f\"Best hyperparameters: {xgboost_results.best_params}\")"
   ],
   "id": "8cbd92b71a5a88bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Track XGBoost results\n",
    "model_results.append({\n",
    "    'model': 'XGBoost',\n",
    "    'rmse': xgboost_results.rmse,\n",
    "    'r2': xgboost_results.r2,\n",
    "    'best_params': xgboost_results.best_params,\n",
    "})\n"
   ],
   "id": "13b2cf96a9ce2268",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Additional Ensemble Methods",
   "id": "2258896860694e55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### AdaBoost",
   "id": "6c9b488e6b21f824"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "adaboost_results = adaboost_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {adaboost_results.best_params}\")"
   ],
   "id": "c4f802750e3eb1e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Mean Squared Error: {adaboost_results.rmse**2:.3f}\")\n",
    "print(f\"Best CV RMSE: {adaboost_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {adaboost_results.r2:.3f}\")\n",
    "\n",
    "best_adaboost_model = adaboost_results.model\n",
    "yhat_ada = adaboost_results.model.predict(X_test_genus)"
   ],
   "id": "afc89b1bf03f8232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat_ada, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level AdaBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8d3ae73d650a72e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importances_ada = pd.Series(\n",
    "    best_adaboost_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances_ada.head(top_n),\n",
    "    y=importances_ada.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera (AdaBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "20b185ba369f7b7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Track AdaBoost results\n",
    "model_results.append({\n",
    "    'model': 'AdaBoost',\n",
    "    'rmse': adaboost_results.rmse,\n",
    "    'r2': adaboost_results.r2,\n",
    "    'best_params': adaboost_results.best_params\n",
    "})"
   ],
   "id": "d1a199b8d137bf79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Boosting",
   "id": "8658b43eb70b871c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "gb_results = gradient_boosting_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {gb_results.best_params}\")"
   ],
   "id": "7d92178658bc71bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Mean Squared Error: {gb_results.rmse**2:.3f}\")\n",
    "print(f\"Best CV RMSE: {gb_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {gb_results.r2:.3f}\")\n",
    "\n",
    "best_gb_model = gb_results.model\n",
    "yhat_gb = gb_results.model.predict(X_test_genus)"
   ],
   "id": "54797f963a503493",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Track Gradient Boosting results\n",
    "model_results.append({\n",
    "    'model': 'Gradient Boosting',\n",
    "    'rmse': gb_results.rmse,\n",
    "    'r2': gb_results.r2,\n",
    "    'best_params': gb_results.best_params\n",
    "})"
   ],
   "id": "bc93e3e3c67454ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat_gb, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level Gradient Boosting)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "48c97e6558845b3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importances_gb = pd.Series(\n",
    "    best_gb_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances_gb.head(top_n),\n",
    "    y=importances_gb.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera (Gradient Boosting)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a5acb836d8a19ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### LightGBM",
   "id": "4b69d8235a72a8e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgb_results = lightgbm_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {lgb_results.best_params}\")"
   ],
   "id": "cbd9cdf01dde5953",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Mean Squared Error: {lgb_results.rmse**2:.3f}\")\n",
    "print(f\"Best CV RMSE: {lgb_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {lgb_results.r2:.3f}\")\n",
    "\n",
    "best_lgb_model = lgb_results.model\n",
    "yhat_lgb = lgb_results.model.predict(X_test_genus)"
   ],
   "id": "cd23ff36a60379dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Track LightGBM results\n",
    "model_results.append({\n",
    "    'model': 'LightGBM',\n",
    "    'rmse': lgb_results.rmse,\n",
    "    'r2': lgb_results.r2,\n",
    "    'best_params': lgb_results.best_params\n",
    "})"
   ],
   "id": "6ed4b40df281e492",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat_lgb, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level LightGBM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6ffedc511d4fb50d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importances_lgb = pd.Series(\n",
    "    best_lgb_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances_lgb.head(top_n),\n",
    "    y=importances_lgb.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera (LightGBM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "21a49c4dd016fb82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stochastic Gradient Boosting\n",
    "\n",
    "Gradient boosting with subsampling for improved generalization."
   ],
   "id": "ae2e9c31ca8ea926"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sgb_results = stochastic_gradient_boosting_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {sgb_results.best_params}\")"
   ],
   "id": "8969a4edbe53c7b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Track Stochastic GB results\n",
    "model_results.append({\n",
    "    'model': 'Stochastic GB',\n",
    "    'rmse': sgb_results.rmse,\n",
    "    'r2': sgb_results.r2,\n",
    "    'best_params': sgb_results.best_params\n",
    "})"
   ],
   "id": "8946456b8c9f45fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Kernel Random Forest\n",
    "\n",
    "Random Forest with kernel approximation for non-linear feature transformation."
   ],
   "id": "fce8a7b63d126013"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kernel_rf_results = kernel_random_forest_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\",\n",
    "    kernel_method=\"nystroem\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {kernel_rf_results.best_params}\")"
   ],
   "id": "2231757c6b52c53e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Track Kernel Random Forest results\n",
    "model_results.append({\n",
    "    'model': 'Kernel Random Forest',\n",
    "    'rmse': kernel_rf_results.rmse,\n",
    "    'r2': kernel_rf_results.r2,\n",
    "    'best_params': kernel_rf_results.best_params\n",
    "})"
   ],
   "id": "42b560bcd859839e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Interpretability",
   "id": "a487499090fc7609"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SHAP (SHapley Additive exPlanations)",
   "id": "1d24676336f3e96f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the Random Forest model for SHAP explanation\n",
    "shap_result = explain_with_shap(\n",
    "    model=best_rf_model,\n",
    "    X_train=X_train_genus,\n",
    "    X_test=X_test_genus,\n",
    "    feature_names=X_train_genus.columns.tolist()\n",
    ")\n",
    "print(f\"\\nSHAP analysis complete for {len(X_test_genus)} test samples\")"
   ],
   "id": "fe706e2bc0dedb67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Summary plot showing feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_result['shap_values'],\n",
    "    X_test_genus,\n",
    "    feature_names=X_train_genus.columns.tolist(),\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "96ae5dd892aa3f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bar plot of mean absolute SHAP values\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_result['shap_values'],\n",
    "    X_test_genus,\n",
    "    feature_names=X_train_genus.columns.tolist(),\n",
    "    plot_type=\"bar\",\n",
    "    max_display=20,\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "1e9a91176bcb5487",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display all model results\n",
    "if model_results:\n",
    "    model_results_df = pd.DataFrame(model_results)\n",
    "\n",
    "    display_df = model_results_df.drop(columns=['best_params'], errors='ignore') #It is not needed to show the parameters\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MODEL RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(display_df.to_string(index=False))\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"No model results collected yet\")\n"
   ],
   "id": "e65fe3277c8e7b7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature Selection Method Comparison\n",
    "\n",
    "Compare different feature selection approaches on the dataset."
   ],
   "id": "b45aa05afc5b1dfd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare PCA, importance-based, and ANOVA feature selection\n",
    "selection_results = compare_feature_selection_methods(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_test,\n",
    "    Y_test,\n",
    "    methods=[\"importance\", \"anova\", \"pca\"],\n",
    "    n_features=[50, 100, 200]\n",
    ")\n",
    "\n",
    "print(\"\\nFeature Selection Comparison Results:\")\n",
    "for method, results in selection_results.items():\n",
    "    print(f\"\\nMethod: {method.capitalize()}:\")\n",
    "    if method == 'baseline':\n",
    "        print(f\"  {data['n_features']} Features: R²={data['r2']:.4f}, RMSE={data['rmse']:.4f}\")\n",
    "    else:\n",
    "        for n_features, metrics in results.items():\n",
    "            print(f\"  {n_features} Features: R²={metrics['r2']:.4f}, RMSE={metrics['rmse']:.4f}\")"
   ],
   "id": "2f3f90d098f8a1c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Selection via neural networks",
   "id": "1d59999d672c450f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The finding",
   "id": "76970736ba9b6a75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "RUN_NN = False\n",
    "if RUN_NN:\n",
    "\n",
    "    USE_GPU = True  # Set to True if GPU is available\n",
    "    if USE_GPU:\n",
    "        # For GPU\n",
    "        nn_res = nn_feature_search(\n",
    "            X_train, X_test, Y_train,\n",
    "            batch_size=8192,\n",
    "            device=\"/GPU:0\",\n",
    "            jit_compile=True,\n",
    "            mixed_precision=True)\n",
    "    else:\n",
    "        # For CPU\n",
    "        nn_res = nn_feature_search(X_train, X_test, Y_train)\n",
    "\n",
    "    if nn_res:\n",
    "        elite_bacteria_list = nn_res.features\n",
    "        print(f\"Selected {nn_res.n_features} elite bacterial drivers.\")\n",
    "        print(f\"Expected Validation RMSE: {nn_res.rmse:.2f} days\")\n",
    "\n",
    "    else:\n",
    "        print(\"No feature set found within the target range.\")"
   ],
   "id": "efe9267d0176f87c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving the NN results",
   "id": "903ed5828183bc25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if RUN_NN:\n",
    "    try:\n",
    "        nn_res.X_train.to_csv('X_train_NN_elite_raw.csv', index=True)\n",
    "        nn_res.X_test.to_csv('X_test_NN_elite_raw.csv', index=True)\n",
    "        print(\"Current NN results saved to CSV.\")\n",
    "        X_train_neural = nn_res.X_train\n",
    "        X_test_neural = nn_res.X_test\n",
    "\n",
    "    except NameError:\n",
    "        print(\"Neural network did not run, trying to load previous results.\")\n",
    "        if os.path.exists('X_train_NN_elite_raw.csv'):\n",
    "            X_train_neural = pd.read_csv('X_train_NN_elite_raw.csv', index_col=0)\n",
    "            X_test_neural = pd.read_csv('X_test_NN_elite_raw.csv', index_col=0)\n",
    "            print(\"Previous NN results loaded successfully.\")\n",
    "        else:\n",
    "            print(\"No previous results found. Neural network comparison will not run.\")\n"
   ],
   "id": "b0d9623e1b6ad48a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing the genus vs neural network features on all models",
   "id": "2a7a7991a673c100"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Feature Cutoff Cross-Validation\n",
    "\n",
    "Test model performance at different taxonomic levels"
   ],
   "id": "a0322da347cb3bc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test Random Forest at different taxonomic levels\n",
    "rf_cutoff_dict, rf_cutoff_df = cross_validate_feature_cutoffs(\n",
    "    X_train_raw,\n",
    "    Y_train,\n",
    "    feature_levels=['Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species'],\n",
    "    cv_folds=5\n",
    ")\n",
    "print(\"\\nResults DataFrame:\")\n",
    "print(rf_cutoff_df)"
   ],
   "id": "dbedd2f5ae5f25db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize the results\n",
    "#TODO: Fix KeyError: 'n_features'\n",
    "#plot_feature_cutoff_comparison(rf_cutoff_dict, title=\"Random Forest Performance\")"
   ],
   "id": "f41ceb9f36b06da1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare Different Models Across Taxonomic Levels",
   "id": "cfa41f81bbc57f6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test other models\n",
    "xgb_cutoff_dict, xgb_cutoff_df = cross_validate_feature_cutoffs(\n",
    "    X_train_raw,\n",
    "    Y_train,\n",
    "    feature_levels=['Phylum', 'Class', 'Order', 'Family', 'Genus'],\n",
    "    cv_folds=5\n",
    ")\n",
    "print(\"\\nResults DataFrame:\")\n",
    "print(xgb_cutoff_df)"
   ],
   "id": "747c85d97f474c7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lgbm_cutoff_dict, lgbm_cutoff_df = cross_validate_feature_cutoffs(\n",
    "    X_train_raw,\n",
    "    Y_train,\n",
    "    feature_levels=['Phylum', 'Class', 'Order', 'Family', 'Genus'],\n",
    "    cv_folds=5\n",
    ")\n",
    "print(\"\\nResults DataFrame:\")\n",
    "print(lgbm_cutoff_df)"
   ],
   "id": "92339a4abed3a855",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Advanced Model Visualizations",
   "id": "f1cb1043fa16679"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Residuals analysis for best Random Forest model\n",
    "plot_residuals_analysis(Y_test, yhat, title=\"Random Forest Residuals Analysis\")"
   ],
   "id": "9cec50612c5f0367",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prediction intervals (showing uncertainty from individual trees)\n",
    "plot_prediction_intervals(\n",
    "    Y_test, \n",
    "    yhat,\n",
    "    prediction_std=rf_std,\n",
    "    sample_indices=range(50),  # Show first 50 samples\n",
    "    title=\"Random Forest Predictions with Uncertainty\"\n",
    ")"
   ],
   "id": "4fbf1af7df0c658",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Learning curves to check for overfitting\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=MASTER_SEED, n_jobs=-1)\n",
    "plot_learning_curves(\n",
    "    rf_model,\n",
    "    X_train_genus,\n",
    "    Y_train,\n",
    "    cv_folds=5,\n",
    "    title=\"Random Forest Learning Curves (Genus Level)\"\n",
    ")"
   ],
   "id": "9e9009bb57087284",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Comparison",
   "id": "d12ca412142e1d10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compare all models (assuming they've been run)\n",
    "try:\n",
    "    # Build a dictionary of all results objects available\n",
    "    comparison_map = {}\n",
    "    if 'rf_results' in locals(): comparison_map['Random Forest'] = rf_results\n",
    "    if 'xgboost_results' in locals(): comparison_map['XGBoost'] = xgboost_results\n",
    "    if 'adaboost_results' in locals(): comparison_map['AdaBoost'] = adaboost_results\n",
    "    if 'gb_results' in locals(): comparison_map['Gradient Boosting'] = gb_results\n",
    "    if 'lgb_results' in locals(): comparison_map['LightGBM'] = lgb_results\n",
    "    if 'sgb_results' in locals(): comparison_map['Stochastic GB'] = sgb_results\n",
    "    if 'kernel_rf_results' in locals(): comparison_map['Kernel RF'] = kernel_rf_results\n",
    "\n",
    "    if comparison_map:\n",
    "        plot_model_comparison_heatmap(comparison_map, title=\"Final Model Performance Comparison\")\n",
    "    else:\n",
    "        print(\"No benchmark results found to plot.\")\n",
    "except NameError as e:\n",
    "    print(f\"Visualization error: {e}\")"
   ],
   "id": "e267032cd25512b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Using best parameters from the genus set\n",
    "try:\n",
    "    feature_sets = {\n",
    "    \"Genus Level\": X_train_genus,\n",
    "    \"Family Level\": X_train_family,\n",
    "    \"Order Level\": X_train_order,\n",
    "    \"Species Level\": X_train_species,\n",
    "    \"Phylum Level\": X_train_phylum,\n",
    "    \"Class Level\": X_train_class\n",
    "    }\n",
    "\n",
    "    battle_stats = final_battle(\n",
    "        feature_sets, Y_train,\n",
    "        n_splits=5, n_repeats=5,\n",
    "        rf_params=rf_results.best_params if 'rf_results' in locals() else None,\n",
    "        xgb_params=xgboost_results.best_params if 'xgboost_results' in locals() else None,\n",
    "        gb_params=gb_results.best_params if 'gb_results' in locals() else None,\n",
    "        lgbm_params=lgb_results.best_params if 'lgb_results' in locals() else None,\n",
    "        ada_params=adaboost_results.best_params if 'adaboost_results' in locals() else None,\n",
    "        sgb_params=sgb_results.best_params if 'sgb_results' in locals() else None,\n",
    "        krf_params=kernel_rf_results.best_params if 'kernel_rf_results' in locals() else None\n",
    "    )\n",
    "except NameError:\n",
    "    print(\"Neural network or Genus data not initialized properly.\")"
   ],
   "id": "b99b5d5c508c3e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Standard DataFrame setup\n",
    "results_df = pd.DataFrame(battle_stats)\n",
    "rmse_col, r2_col, std_col = 'RMSE_Mean', 'R2_Mean', 'RMSE_Std'\n",
    "\n",
    "# 2. Create the Pro Dark Styled Table\n",
    "# We hide the index to remove the row numbers\n",
    "pro_table = results_df.sort_values(rmse_col).style.hide(axis='index').set_properties(**{\n",
    "    'background-color': 'black',\n",
    "    'color': 'white',\n",
    "    'border-color': '#444444'\n",
    "})\n",
    "\n",
    "# 3. Apply the Gradients\n",
    "# RMSE: Green (low) to Red (high)\n",
    "pro_table = pro_table.background_gradient(subset=[rmse_col], cmap='RdYlGn_r')\n",
    "# R2: Red (low) to Green (high)\n",
    "pro_table = pro_table.background_gradient(subset=[r2_col], cmap='RdYlGn')\n",
    "\n",
    "# 4. Apply Formatting\n",
    "pro_table = pro_table.format({\n",
    "    rmse_col: \"{:.2f} days\",\n",
    "    r2_col: \"{:.3f}\",\n",
    "    std_col: \"±{:.2f}\"\n",
    "})\n",
    "\n",
    "# Display in notebook\n",
    "pro_table"
   ],
   "id": "95a7e715a947ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation Metrics Analysis\n",
    "\n",
    "Determine the best evaluation metric for model performance."
   ],
   "id": "5ecc3b3430659aaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TODO: Put the winning model from the final_battle() and parameters by cross-validation\n",
    "# Get best evaluation metrics for the top model\n",
    "# Using predictions from the best model (e.g., Random Forest)\n",
    "best_metrics = find_best_evaluation_metric(Y_test, rf_results.model.predict(X_test_genus))\n",
    "print(\"\\nBest Evaluation Metrics:\")\n",
    "for metric, value in best_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ],
   "id": "95cb217e7f87d983",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
