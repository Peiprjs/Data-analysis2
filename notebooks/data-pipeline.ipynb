{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Housekeeping",
   "id": "245a8e452ba91453"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Library imports",
   "id": "b20a48091de21310"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if True:\n",
    "    pass\n",
    "    !{sys.executable} -m pip install -r requirements.txt"
   ],
   "id": "6a35b206f820bd0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Core Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Machine Learning - Core\n",
    "import sklearn\n",
    "from colorama import Fore, Style\n",
    "# Statistical & Data Processing\n",
    "from scipy import stats\n",
    "# Machine Learning - Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from supertree import SuperTree\n",
    "\n",
    "# Model Interpretability\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom Functions"
   ],
   "id": "e8b0c9e23b360a57",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Imports (for specific analyses)\n",
    "\n",
    "These imports are used for specific visualizations and analyses that may not be needed in every run."
   ],
   "id": "2fd612228f841190"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Optional: Advanced Visualizations\n",
    "# from sklearn.decomposition import PCA\n",
    "# from click.format import wrap_text  # May not be needed\n",
    "# import collections  # Built-in, no install needed\n",
    "\n",
    "# Note: Most visualization functions are now in functions.py\n",
    "# and imported above in the main imports cell"
   ],
   "id": "a94ed1c5ed2a3223",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Settings",
   "id": "22f6afe07dae0590"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "print(Style.RESET_ALL)"
   ],
   "id": "f6f6ef7d9493cd17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data imports\n",
    "Data was manually edited, to convert the mpa411.txt TSV format to a CSV format. Otherwise, Pandas was loading it as a single column, somehow. The first row, containing only \"#mpa_vJun23_CHOCOPhlAnSGB_202403\" was removed."
   ],
   "id": "a9398ff41d8ed543"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('../data/raw/MAI3004_lucki_mpa411.csv')\n",
    "metadata = pd.read_csv('../data/raw/MAI3004_lucki_metadata_safe.csv')\n",
    "print(\n",
    "    f\"Data successfully imported. \\n shape of data: {data.shape} \\n \"\n",
    "    f\"Shape of metadata: {metadata.shape}\"\n",
    ")\n",
    "\n",
    "assert data.shape == (6903, 932), \"Data has the wrong shape. Check the CSV formatting.\"\n",
    "assert metadata.shape == (930, 6), \"Metadata has the wrong shape. Check the CSV formatting.\"\n"
   ],
   "id": "890e64ba932e7f65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Function definitions\n",
    "| Function Name | Description | Parameters |\n",
    "|---------------|-------------|------------|\n"
   ],
   "id": "9d21d71d1c214e8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data preprocessing",
   "id": "5e9f672bf329ed95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merge data and metadata",
   "id": "126792a1db6fb384"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sample_cols = [col for col in data.columns if col.startswith(\"mpa411_\")]\n",
    "\n",
    "sample_abundances = (\n",
    "    data[['clade_name'] + sample_cols]\n",
    "    .set_index('clade_name')\n",
    "    .transpose()\n",
    "    .rename_axis('original_sample_id')\n",
    "    .reset_index()\n",
    "    .rename(columns={'original_sample_id': 'sample_id'})\n",
    ")\n",
    "\n",
    "sample_abundances[\"sample_id\"] = (\n",
    "    sample_abundances[\"sample_id\"].str.removeprefix(\n",
    "        \"mpa411_\",\n",
    "    )\n",
    ")\n",
    "\n",
    "metadata_common = metadata[\n",
    "    metadata[\"sample_id\"].isin(sample_abundances[\"sample_id\"])\n",
    "].copy()\n",
    "merged_samples = metadata_common.merge(\n",
    "    sample_abundances,\n",
    "    on=\"sample_id\",\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "merged_samples.drop(columns=['year_of_birth', 'body_product'], inplace=True)\n",
    "# YOB and body_product are omitted without sample dates.\n",
    "# All samples are fecal.\n",
    "# TODO: should we be accounting for sex? Do statistical analysis\n",
    "\n",
    "print(f\"Metadata rows (original): {metadata.shape[0]}\")\n",
    "print(f\"Metadata rows with matching samples: {metadata_common.shape[0]}\")\n",
    "print(\n",
    "    f\"Metadata rows without matching samples: \"\n",
    "    f\"{metadata_common.shape[0]-metadata_common.shape[0]}\"\n",
    ")\n",
    "print(f\"Merged dataframe shape: {merged_samples.shape}\")"
   ],
   "id": "cb744291054dc1d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged_samples.head()",
   "id": "8ae00915d8eb3714",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Encoding",
   "id": "226450d88bcae44c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sex and family_ID\n",
    "encoded_samples = merged_samples.copy().dropna(subset=\"age_group_at_sample\")\n",
    "\n",
    "encoded_samples[\"sex\"] = (\n",
    "    encoded_samples[\"sex\"]\n",
    "    .fillna(\"unknown\")\n",
    "    .replace({\"female\": 1, \"male\": 0, \"unknown\": 2})\n",
    ")\n",
    "encoded_samples[\"family_id\"] = LabelEncoder().fit_transform(\n",
    "    encoded_samples[\"family_id\"]\n",
    ")\n"
   ],
   "id": "f0b746a5253a72f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Using days to better interpret the distance between age groups\n",
    "encoding_guide = {\n",
    "    '1-2 weeks': 10,\n",
    "    '4 weeks': 28,\n",
    "    '8 weeks': 56,\n",
    "    '4 months': 120,\n",
    "    '5 months': 150,\n",
    "    '6 months': 180,\n",
    "    '9 months': 270,\n",
    "    '11 months': 330,\n",
    "    '14 months': 420,\n",
    "}\n",
    "encoded_samples[\"age_group_at_sample\"].replace(encoding_guide, inplace=True)\n",
    "\n",
    "# consider in interpretation that the distances between the real age bins are not the same as our age groups"
   ],
   "id": "aa6e8781f0d48498",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if False in pd.DataFrame(encoded_samples[\"age_group_at_sample\"]).applymap(np.isreal): #fallback encoder\n",
    "    age_encoder = LabelEncoder().fit(encoded_samples[\"age_group_at_sample\"])\n",
    "    encoded_samples[\"age_group_at_sample\"] = age_encoder.transform(\n",
    "        encoded_samples[\"age_group_at_sample\"]\n",
    "    )\n",
    "\n",
    "    age_groups = dict(\n",
    "        zip(age_encoder.classes_, age_encoder.transform(age_encoder.classes_))\n",
    "    )\n",
    "    print(\"Age group encoding:\", age_groups)\n",
    "\n",
    "else:\n",
    "    print(\"Fallback encoding not needed\")"
   ],
   "id": "88e9447f0a7d066f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Missing check",
   "id": "ecd816ad7b428824"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "missing_table = (\n",
    "    encoded_samples.isna()\n",
    "    .sum()\n",
    "    .to_frame(name=\"missing_count\")\n",
    "    .assign(\n",
    "        missing_percent=lambda df: (\n",
    "            (df[\"missing_count\"] / encoded_samples.shape[0] * 100).round(2)\n",
    "        ),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"column\"})\n",
    "    .sort_values(\"missing_count\", ascending=False)\n",
    "    .query(\"missing_count != 0\")\n",
    ")\n",
    "\n",
    "if len(missing_table) > 0:\n",
    "    missing_table\n",
    "else:\n",
    "    print(\"No missing values detected.\")"
   ],
   "id": "626e444ee2e1fb9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Outlier check",
   "id": "bbdfec74a7c54fb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "numeric_cols = encoded_samples.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "q1 = encoded_samples[numeric_cols].quantile(0.25)\n",
    "q3 = encoded_samples[numeric_cols].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bounds = q1 - 1.5 * iqr\n",
    "upper_bounds = q3 + 1.5 * iqr\n",
    "\n",
    "outlier_mask = (\n",
    "    (encoded_samples[numeric_cols] < lower_bounds)\n",
    "    | (encoded_samples[numeric_cols] > upper_bounds)\n",
    ")\n",
    "outlier_counts = outlier_mask.sum()\n",
    "outlier_percent = (outlier_counts / encoded_samples.shape[0] * 100).round(2)\n",
    "\n",
    "outlier_table = (\n",
    "    pd.DataFrame({\n",
    "        \"column\": numeric_cols,\n",
    "        \"lower_bound\": lower_bounds,\n",
    "        \"upper_bound\": upper_bounds,\n",
    "        \"outlier_count\": outlier_counts,\n",
    "        \"outlier_percent\": outlier_percent,\n",
    "    })\n",
    "    .query(\"outlier_count > 0\")\n",
    "    .sort_values(\"outlier_percent\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "outlier_table"
   ],
   "id": "32aa2bc69f3bd02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalisation check",
   "id": "c9a10115d763bdb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "normalized_samples = encoded_samples.copy()\n",
    "print(\"Shapiro-Wilk Normality Test\")\n",
    "\n",
    "for column in numeric_cols:\n",
    "    data_nona = normalized_samples[column].dropna()\n",
    "    stat, p_value = stats.shapiro(data_nona)\n",
    "\n",
    "    if p_value > 0.05:\n",
    "        print(Fore.GREEN + f\"{column}: Normally Distributed (p={p_value:.4f})\")\n",
    "\n",
    "    else:\n",
    "        print(\n",
    "            Fore.RED\n",
    "            + f\"{column}: Not Normally Distributed (p={p_value:.4f})\"\n",
    "        )\n",
    "\n",
    "print(Style.RESET_ALL)"
   ],
   "id": "ee40e5c046a69e52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train-test split before pre-processing",
   "id": "3619d97a8599c6ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "feature_cols = normalized_samples.columns.difference([\"sample_id\", \"age_group_at_sample\"]) # These variables will get removed from X\n",
    "\n",
    "X = normalized_samples[feature_cols]\n",
    "Y = normalized_samples[\"age_group_at_sample\"]\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=3004)\n",
    "train_indicies, test_indicies = next(gss.split(X, Y, groups=X['family_id']))\n",
    "X_train_raw = X.iloc[train_indicies]\n",
    "X_test_raw = X.iloc[test_indicies]\n",
    "Y_train = Y.iloc[train_indicies]\n",
    "Y_test = Y.iloc[test_indicies]\n",
    "\n",
    "assert X_train_raw.shape[1] == X_test_raw.shape[1], \"Feature columns do not match between train and test sets.\"\n",
    "assert X_train_raw.shape[0] == Y_train.shape[0] and X_test_raw.shape[0] == Y_test.shape[0], \"X and Y do not have the same length.\"\n",
    "\n",
    "print(\"Train shape:\", X_train_raw.shape, \"| Test shape:\", X_test_raw.shape)"
   ],
   "id": "80e1fc5192fa796b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalising data using clr transformation",
   "id": "64f8805ca3d312a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"The CLR function based on: https://medium.com/@nextgendatascientist/a-guide-for-data-scientists-log-ratio-transformations-in-machine-learning-a2db44e2a455\"\"\"\n",
    "\n",
    "def clr_transform(X, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Compute CLR with a tunable zero-replacement value (epsilon).\n",
    "    \"\"\"\n",
    "\n",
    "    #To capture metadata from the original dataframe\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        index = X.index\n",
    "        columns = X.columns\n",
    "        X_arr = X.values\n",
    "    else:\n",
    "        X_arr = X\n",
    "\n",
    "    # 1. Replace zeros with epsilon (tunable parameter)\n",
    "    X_replaced = np.where(X == 0, epsilon, X)\n",
    "\n",
    "    # 2. Compute Geometric Mean\n",
    "    # exp(mean(log)) is safer and standard for this\n",
    "    gm = np.exp(np.log(X_replaced).mean(axis=1, keepdims=True))\n",
    "\n",
    "    # 3. CLR transformation\n",
    "    X_clr = np.log(X_replaced / gm)\n",
    "\n",
    "\n",
    "    #Rebulding back a NumPy array to a dataframe\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        return pd.DataFrame(X_clr, index=index, columns=columns)\n",
    "\n",
    "    return X_clr"
   ],
   "id": "84265063914f513a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train = clr_transform(X_train_raw)\n",
    "X_test = clr_transform(X_test_raw)"
   ],
   "id": "193f715fbca3525a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#To activate back the raw data without normalisation\n",
    "\n",
    "#X_train = X_train_raw\n",
    "#X_test = X_test_raw"
   ],
   "id": "3b484009d29a58d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Shapiro-Wilk Normality Test (after Log Normlaisation)\\n\")\n",
    "\n",
    "for col in X_train.columns:\n",
    "\n",
    "    # 1. Get the data for this column from both sets\n",
    "    train_data = X_train[col].dropna()\n",
    "    test_data = X_test[col].dropna()\n",
    "\n",
    "    # 2. Run Shapiro test on both\n",
    "    stat_train, p_train = stats.shapiro(train_data)\n",
    "    stat_test, p_test = stats.shapiro(test_data)\n",
    "\n",
    "    # 3. Determine status (Both must be > 0.05 to be truly \"Normal\")\n",
    "    is_train_normal = p_train > 0.05\n",
    "    is_test_normal = p_test > 0.05\n",
    "\n",
    "    # 4. Print Logic\n",
    "    # If both are Green\n",
    "    if is_train_normal and is_test_normal:\n",
    "        print(Fore.GREEN + f\"✔ {col}: Normal (Train p={p_train:.3f}, Test p={p_test:.3f})\")\n",
    "\n",
    "    # If one is Red (Mixed results)\n",
    "    elif is_train_normal or is_test_normal:\n",
    "        print(Fore.YELLOW + f\"⚠ {col}: Inconsistent (Train p={p_train:.3f}, Test p={p_test:.3f})\")\n",
    "\n",
    "    # If both are Red\n",
    "    else:\n",
    "        print(Fore.RED + f\"✘ {col}: Not Normal (Train p={p_train:.3f}, Test p={p_test:.3f})\")\n",
    "\n",
    "print(Style.RESET_ALL)"
   ],
   "id": "b7ed25037599f315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exploratory data analysis",
   "id": "ec8214ce5862d929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(merged_samples.shape)\n",
    "merged_samples.head()"
   ],
   "id": "7155f5c71e429871",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset overview\n",
    "print(\"Number of samples:\", len(merged_samples))\n",
    "print(\n",
    "    \"Number of unique families (family_id):\",\n",
    "    merged_samples[\"family_id\"].nunique(),\n",
    ")\n",
    "print(\"Number of columns (metadata + features):\", merged_samples.shape[1])"
   ],
   "id": "3d80e74f7efff9f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Samples per family\n",
    "samples_per_family = merged_samples[\"family_id\"].value_counts()\n",
    "samples_per_family.describe()"
   ],
   "id": "2bc5e5d2f5f063fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "samples_per_family.hist(bins=20)\n",
    "plt.xlabel(\"Number of samples per family\")\n",
    "plt.ylabel(\"Number of families\")\n",
    "plt.title(\"Distribution of samples per family\")\n",
    "plt.show()"
   ],
   "id": "dc1423022712d7ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#distribution of age groups\n",
    "merged_samples[\"age_group_at_sample\"].value_counts(dropna=False)"
   ],
   "id": "c230c5e3ee6a406a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged_samples[\"age_group_at_sample\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of age groups\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "id": "991cc1e66db3db86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#dimensionality and sparsity of the microbiome feature matrix\n",
    "metadata_cols = [\n",
    "    \"sample_id\",\n",
    "    \"family_id\",\n",
    "    \"sex\",\n",
    "    \"body_product\",\n",
    "    \"age_group_at_sample\",\n",
    "    \"year_of_birth\",\n",
    "]\n",
    "feature_cols = [c for c in merged_samples.columns if c not in metadata_cols]\n",
    "\n",
    "X = merged_samples[feature_cols]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Overall fraction of zeros:\", (X == 0).mean().mean())"
   ],
   "id": "4e8ac4dc9ae13c10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#number of observed taxa per sample\n",
    "nonzero_per_sample = (X > 0).sum(axis=1)\n",
    "nonzero_per_sample.describe()"
   ],
   "id": "9cfccc0be8ba7125",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nonzero_per_sample.hist(bins=50)\n",
    "plt.xlabel(\"Number of non-zero taxa per sample\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Non-zero taxa per sample\")\n",
    "plt.show()"
   ],
   "id": "5ca8d17368c32eea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Total abundance per sample (sanity check)\n",
    "total_abundance = X.sum(axis=1)\n",
    "total_abundance.describe()"
   ],
   "id": "813d8e69f9ef8a2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "total_abundance.hist(bins=50)\n",
    "plt.xlabel(\"Total abundance per sample\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Total microbial abundance per sample\")\n",
    "plt.show()"
   ],
   "id": "36d47d0499c2ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution of feature prevalence\n",
    "feature_prevalence = (X > 0).sum(axis=0)\n",
    "feature_prevalence.describe()"
   ],
   "id": "783cb2d28a53d27f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "feature_prevalence.hist(bins=50)\n",
    "plt.xlabel(\"Number of samples in which taxon is present\")\n",
    "plt.ylabel(\"Number of taxa\")\n",
    "plt.title(\"Feature prevalence distribution\")\n",
    "plt.show()"
   ],
   "id": "5281aa43e4562459",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution of non-zero abundances (log scale)\n",
    "\n",
    "nonzero_values = X.values[X.values > 0]\n",
    "plt.hist(np.log10(nonzero_values), bins=50)\n",
    "plt.xlabel(\"log10(abundance)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of non-zero abundances (log10 scale)\")\n",
    "plt.show()"
   ],
   "id": "db926589f449cd18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PCA visualization\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Use a subset of features for speed\n",
    "prevalence = (X > 0).sum(axis=0)\n",
    "top_features = prevalence.sort_values(ascending=False).head(500).index\n",
    "\n",
    "X_sub = X[top_features]\n",
    "\n",
    "# Scale features\n",
    "X_scaled = StandardScaler().fit_transform(X_sub)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot\n",
    "age = merged_samples[\"age_group_at_sample\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca.iloc[:, 0], X_pca.iloc[:, 1],\n",
    "            c=pd.factorize(age)[0], cmap=\"viridis\", alpha=0.6)\n",
    "plt.colorbar(label=\"Age group (encoded)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.title(\"PCA of samples colored by age group\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)"
   ],
   "id": "54f02d274a912fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary of EDA\n",
    "The dataset consists of 930 stool samples derived from multiple individuals across different families and contains approximately 6,900 microbiome features, making it a high-dimensional and highly sparse dataset. Each sample contains on average around 300 detected taxa, while the total microbial abundance per sample is relatively stable, indicating that sequencing depth is consistent across samples.\n",
    "Most taxa are rare and occur in only a small fraction of samples, whereas a small subset of taxa is highly prevalent across the cohort. The distribution of non-zero abundances follows an approximately log-normal shape, which is typical for microbiome sequencing data (e.g., Lutz et al., 2022).\n",
    "A PCA projection based on the most prevalent taxa does not reveal sharply separated clusters but shows a gradual age-related gradient, suggesting that age-related variation in microbiome composition is present but represents only a limited fraction of the total variance in the data."
   ],
   "id": "f7530865cf36e986"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Training",
   "id": "8cbfbf00358f394f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Filtering for features at the genus level",
   "id": "a2e2424b2ba2f42e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def filter_genus(df_uf): #Defining a function that filters a dataframe to only include columns with features at genus level\n",
    "    df_uf = df_uf.drop(list(df_uf.filter(regex=\"s__\")),axis=1,inplace=False) #Drops columns that include features at species level\n",
    "    df_uf = df_uf.filter(regex=\"g__\") #Drops columns that include features broader than genus level\n",
    "    return df_uf"
   ],
   "id": "4bcf513db7515b8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_genus = filter_genus(X_train)\n",
    "X_test_genus = filter_genus(X_test)"
   ],
   "id": "866229db722bbf2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "\"target_names\" in X_train_genus.columns",
   "id": "4094ea110df59e74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"Features used by model:\")\n",
    "print(X_train_genus.columns.tolist())"
   ],
   "id": "ad098b321d34960d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random Forest Regressor with Train/Test split (Genus)",
   "id": "7d59a7755b1444f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Base model",
   "id": "a9131d8365d705cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Base model\n",
    "rf_base = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    oob_score=True\n",
    ")\n",
    "\n",
    "rf_base.fit(X_train_genus, Y_train)\n",
    "yhat_rf = rf_base.predict(X_test_genus)\n",
    "\n",
    "print(f\"Mean Squared Error: {mean_squared_error(Y_test, yhat_rf):.3f}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(mean_squared_error(Y_test, yhat_rf)):.3f}\")\n",
    "print(f\"R2 Score: {r2_score(Y_test, yhat_rf):.3f}\")\n"
   ],
   "id": "eda7d7dc405462a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Search for the best model",
   "id": "f2b359f109ab90c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functions import random_forest_benchmark\n",
    "\n",
    "rf_results = random_forest_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {rf_results.best_params}\")"
   ],
   "id": "8661bb165827c72c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Mean Squared Error: {rf_results.rmse**2:.3f}\") # Squared because rmse is sqrt(mse)\n",
    "print(f\"Best CV RMSE: {rf_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {rf_results.r2:.3f}\")\n",
    "\n",
    "best_rf_model = rf_results.model\n",
    "yhat = rf_results.model.predict(X_test_genus)"
   ],
   "id": "f9364a0806c336f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level RF)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ad574d564c7852a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "residuals = Y_test - yhat\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x=yhat, y=residuals, alpha=0.6)\n",
    "plt.axhline(0, linestyle=\"--\", color=\"red\")\n",
    "\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs Predictions\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "8da57ad565f614b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "importances = pd.Series(\n",
    "    best_rf_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances.head(top_n),\n",
    "    y=importances.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6e8a5f262b8fc84d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "st = SuperTree(\n",
    "    best_rf_model,\n",
    "    X_train_genus,\n",
    "    Y_train\n",
    ")\n",
    "\n",
    "st.show_tree(which_tree=0)"
   ],
   "id": "b052a6d63b392ba6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get predictions from each tree on the test set\n",
    "all_tree_preds = np.array([tree.predict(X_test_genus) for tree in best_rf_model.estimators_])\n",
    "\n",
    "# compute the mean prediction (Random Forest final prediction)\n",
    "rf_pred = all_tree_preds.mean(axis=0)\n",
    "\n",
    "# compute standard deviation per sample (uncertainty)\n",
    "rf_std = all_tree_preds.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# plot all tree predictions (semi-transparent lines)\n",
    "for i in range(all_tree_preds.shape[0]):\n",
    "    plt.plot(Y_test.values, all_tree_preds[i], 'o', color='lightgray', alpha=0.3)\n",
    "\n",
    "# plot Random Forest mean prediction\n",
    "plt.scatter(Y_test, rf_pred, color='blue', label='RF mean prediction', s=40)\n",
    "\n",
    "plt.errorbar(Y_test, rf_pred, yerr=rf_std, fmt='o', color='red', alpha=0.5, label='±1 std across trees')\n",
    "\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color='black', linestyle='--', label='Perfect prediction')\n",
    "\n",
    "plt.xlabel(\"Actual Age Group\")\n",
    "plt.ylabel(\"Predicted Age Group\")\n",
    "plt.title(\"Random Forest – Forest plot of tree predictions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "970874b827cb2a7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Alternative Models",
   "id": "c0793638701d012a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## XGBoost Alternative",
   "id": "89d196cc9e1d8306"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from xgboost import XGBRegressor\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Base model\n",
    "xgb_base = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "X_train_clean = X_train_genus.copy()\n",
    "X_train_clean.columns = [re.sub('[^A-Za-z0-9_]+', '', str(col)) for col in X_train_clean.columns]\n",
    "X_test_clean = X_test_genus.copy()\n",
    "X_test_clean.columns = [re.sub('[^A-Za-z0-9_]+', '', str(col)) for col in X_test_clean.columns]\n",
    "\n",
    "\n",
    "xgb_base.fit(X_train_clean, Y_train)\n",
    "yhat_xgb = xgb_base.predict(X_test_clean)\n",
    "\n",
    "print(f\"Mean Squared Error: {mean_squared_error(Y_test, yhat_xgb):.3f}\")\n",
    "print(f\"Best CV RMSE: {np.sqrt(mean_squared_error(Y_test, yhat_xgb)):.3f}\")\n",
    "print(f\"R2 Score: {r2_score(Y_test, yhat_xgb):.3f}\")\n",
    "\n",
    "#Best hyperparameters: {'subsample': 0.7, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 0.2}"
   ],
   "id": "5ac4ab60ebe633dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Best XGBoost Parameters Search",
   "id": "81a41726ab4ede0f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c750bebd9b3f2534",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ensemble Methods"
   ],
   "id": "cef54e7c9a22d20e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ],
   "id": "1709dea05f807bbd"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functions import adaboost_benchmark\n",
    "\n",
    "adaboost_results = adaboost_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {adaboost_results.best_params}\")"
   ],
   "id": "be90aefc3c6783d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"Mean Squared Error: {adaboost_results.rmse**2:.3f}\")\n",
    "print(f\"Best CV RMSE: {adaboost_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {adaboost_results.r2:.3f}\")\n",
    "\n",
    "best_adaboost_model = adaboost_results.model\n",
    "yhat_ada = adaboost_results.model.predict(X_test_genus)"
   ],
   "id": "cf8d60a10dc263e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat_ada, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level AdaBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "76481b7a7673791d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importances_ada = pd.Series(\n",
    "    best_adaboost_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances_ada.head(top_n),\n",
    "    y=importances_ada.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera (AdaBoost)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4d38e2a3dae4e999",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ],
   "id": "5d5f18047f1814fe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "from functions import gradient_boosting_benchmark\n",
    "\n",
    "gb_results = gradient_boosting_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {gb_results.best_params}\")"
   ],
   "id": "9d2691c8d0d358ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"Mean Squared Error: {gb_results.rmse**2:.3f}\")\n",
    "print(f\"Best CV RMSE: {gb_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {gb_results.r2:.3f}\")\n",
    "\n",
    "best_gb_model = gb_results.model\n",
    "yhat_gb = gb_results.model.predict(X_test_genus)"
   ],
   "id": "2d8bda412a5c95c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat_gb, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level Gradient Boosting)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5b1a082b5b56e80",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importances_gb = pd.Series(\n",
    "    best_gb_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances_gb.head(top_n),\n",
    "    y=importances_gb.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera (Gradient Boosting)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "48921fdf9c021201",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ],
   "id": "466b9afa8de59147"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functions import lightgbm_benchmark\n",
    "\n",
    "lgb_results = lightgbm_benchmark(\n",
    "    X_train_genus,\n",
    "    X_test_genus,\n",
    "    Y_train,\n",
    "    Y_test,\n",
    "    label=\"Genus Level\"\n",
    ")\n",
    "\n",
    "print(f\"\\nBest hyperparameters: {lgb_results.best_params}\")"
   ],
   "id": "9fdb9a60b2716815",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"Mean Squared Error: {lgb_results.rmse**2:.3f}\")\n",
    "print(f\"Best CV RMSE: {lgb_results.rmse:.3f}\")\n",
    "print(f\"R2 Score: {lgb_results.r2:.3f}\")\n",
    "\n",
    "best_lgb_model = lgb_results.model\n",
    "yhat_lgb = lgb_results.model.predict(X_test_genus)"
   ],
   "id": "df1ab292a941f2e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=Y_test, y=yhat_lgb, alpha=0.6)\n",
    "plt.plot([Y_test.min(), Y_test.max()],\n",
    "         [Y_test.min(), Y_test.max()],\n",
    "         color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Predicted vs Actual (Genus-level LightGBM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fe3282455bb75fc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "importances_lgb = pd.Series(\n",
    "    best_lgb_model.feature_importances_,\n",
    "    index=X_train_genus.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "top_n = 20\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(\n",
    "    x=importances_lgb.head(top_n),\n",
    "    y=importances_lgb.head(top_n).index\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Feature importance\")\n",
    "plt.ylabel(\"Genus\")\n",
    "plt.title(f\"Top {top_n} most important genera (LightGBM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fa87a9c4cbb10bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretability with LIME and SHAP"
   ],
   "id": "e33b0c8b290a47d5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME (Local Interpretable Model-agnostic Explanations)"
   ],
   "id": "d6ab0f0131613b0"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functions import explain_with_lime\n",
    "\n",
    "# Use the Random Forest model for explanation\n",
    "lime_explanations = explain_with_lime(\n",
    "    model=best_rf_model,\n",
    "    X_train=X_train_genus,\n",
    "    X_test=X_test_genus,\n",
    "    feature_names=X_train_genus.columns.tolist(),\n",
    "    num_samples=3,\n",
    "    num_features=10\n",
    ")\n",
    "\n",
    "print(\"LIME Explanations for Random Forest Model:\")\n",
    "print(f\"Number of samples explained: {len(lime_explanations)}\")"
   ],
   "id": "6e44b36ac94ae32f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Display explanation for first sample\n",
    "for sample_idx, explanation in lime_explanations.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Sample {sample_idx}:\")\n",
    "    print(f\"Predicted value: {explanation['predicted_value']:.3f}\")\n",
    "    print(f\"Actual value: {explanation['actual_value']:.3f}\")\n",
    "    print(f\"\\nTop contributing features:\")\n",
    "    for feature, weight in explanation['explanation'][:10]:\n",
    "        print(f\"  {feature}: {weight:+.4f}\")"
   ],
   "id": "d17fcb8940fcde59",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP (SHapley Additive exPlanations)"
   ],
   "id": "cb5f4526dcfc0083"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functions import explain_with_shap\n",
    "\n",
    "# Use the Random Forest model for SHAP explanation\n",
    "shap_result = explain_with_shap(\n",
    "    model=best_rf_model,\n",
    "    X_train=X_train_genus,\n",
    "    X_test=X_test_genus,\n",
    "    feature_names=X_train_genus.columns.tolist(),\n",
    "    background_samples=100\n",
    ")\n",
    "\n",
    "print(\"SHAP Analysis Complete\")\n",
    "print(f\"SHAP values shape: {shap_result['shap_values'].shape}\")"
   ],
   "id": "389003fbbd0974ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import shap\n",
    "\n",
    "# Summary plot showing feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_result['shap_values'],\n",
    "    X_test_genus,\n",
    "    feature_names=X_train_genus.columns.tolist(),\n",
    "    max_display=20,\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b5289fb28d40256e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Bar plot of mean absolute SHAP values\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_result['shap_values'],\n",
    "    X_test_genus,\n",
    "    feature_names=X_train_genus.columns.tolist(),\n",
    "    plot_type=\"bar\",\n",
    "    max_display=20,\n",
    "    show=False\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e481edd319adc28b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Selection via neural networks",
   "id": "2c98c1eec8ab3f95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The finding",
   "id": "e5a976626863a1fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functions import nn_feature_search\n",
    "if False:\n",
    "    nn_res = nn_feature_search(X_train, X_test, Y_train)\n",
    "\n",
    "    if nn_res:\n",
    "        elite_bacteria_list = nn_res.feature_names\n",
    "        print(f\"Selected {nn_res.n_features} elite bacterial drivers.\")\n",
    "        print(f\"Expected Validation RMSE: {nn_res.rmse:.2f} days\")\n",
    "    else:\n",
    "        print(\"No feature set found within the target range.\")"
   ],
   "id": "3ab54511c1ce4904",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Comparing the genus vs neural network features on all models",
   "id": "199b9283e701d8f9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Cutoff Cross-Validation\n",
    "\n",
    "Test model performance at different taxonomic levels"
   ],
   "id": "f2272389b734f09d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functions import cross_validate_feature_cutoffs, plot_feature_cutoff_comparison\n",
    "\n",
    "# Test Random Forest at different taxonomic levels\n",
    "rf_cutoff_results = cross_validate_feature_cutoffs(\n",
    "    X_train_raw,\n",
    "    Y_train,\n",
    "    feature_levels=['Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species'],\n",
    "    model_type='RandomForest',\n",
    "    cv_folds=5\n",
    ")"
   ],
   "id": "bfc78a6667aa9a19",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize the results\n",
    "plot_feature_cutoff_comparison(rf_cutoff_results, title=\"Random Forest Performance\")"
   ],
   "id": "6532af3688550c52",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Different Models Across Taxonomic Levels"
   ],
   "id": "5b43e26f43ecac7a"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Test other models\n",
    "xgb_cutoff_results = cross_validate_feature_cutoffs(\n",
    "    X_train_raw,\n",
    "    Y_train,\n",
    "    feature_levels=['Phylum', 'Class', 'Order', 'Family', 'Genus'],\n",
    "    model_type='XGBoost',\n",
    "    cv_folds=5\n",
    ")"
   ],
   "id": "e56ed6ccce0657a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lgbm_cutoff_results = cross_validate_feature_cutoffs(\n",
    "    X_train_raw,\n",
    "    Y_train,\n",
    "    feature_levels=['Phylum', 'Class', 'Order', 'Family', 'Genus'],\n",
    "    model_type='LightGBM',\n",
    "    cv_folds=5\n",
    ")"
   ],
   "id": "e3be1b4df3e2b3af",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model Visualizations"
   ],
   "id": "2cd542b6c3acdc4c"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functions import plot_residuals_analysis, plot_prediction_intervals, plot_learning_curves\n",
    "\n",
    "# Residuals analysis for best Random Forest model\n",
    "plot_residuals_analysis(Y_test, yhat, title=\"Random Forest Residuals Analysis\")"
   ],
   "id": "4d89ff230f676dab",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prediction intervals (showing uncertainty from individual trees)\n",
    "plot_prediction_intervals(\n",
    "    Y_test, \n",
    "    yhat,\n",
    "    prediction_std=rf_std,\n",
    "    sample_indices=range(50),  # Show first 50 samples\n",
    "    title=\"Random Forest Predictions with Uncertainty\"\n",
    ")"
   ],
   "id": "10175d3360e2b0dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Learning curves to check for overfitting\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "plot_learning_curves(\n",
    "    rf_model,\n",
    "    X_train_genus,\n",
    "    Y_train,\n",
    "    cv_folds=5,\n",
    "    title=\"Random Forest Learning Curves (Genus Level)\"\n",
    ")"
   ],
   "id": "c922136e1dc1a641",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ],
   "id": "ee3a31053fb21e6f"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from functions import plot_model_comparison_heatmap\n",
    "\n",
    "# Compare all models (assuming they've been run)\n",
    "try:\n",
    "    model_results = {\n",
    "        'Random Forest': rf_results,\n",
    "        'AdaBoost': ada_results,\n",
    "        'Gradient Boosting': gb_results,\n",
    "        'LightGBM': lgbm_results\n",
    "    }\n",
    "    plot_model_comparison_heatmap(model_results, title=\"Model Performance Comparison\")\n",
    "except NameError:\n",
    "    print(\"Some models haven't been run yet. Run all benchmark functions first.\")"
   ],
   "id": "b0c02e58adbd0729",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functions import final_battle\n",
    "try:\n",
    "    nn_res\n",
    "except NameError:\n",
    "    print(\"Neural network did not run\")\n",
    "else:\n",
    "        feature_sets = {\n",
    "        \"Genus Level\": X_train_genus,\n",
    "        \"NN Level\": nn_res.X_train_elite\n",
    "    }\n",
    "        battle_stats = final_battle(feature_sets, Y_train)\n"
   ],
   "id": "802c3b1fc04a2922",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
